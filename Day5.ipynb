{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e188e2c",
   "metadata": {},
   "source": [
    "# Day 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f455e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40b0b5c",
   "metadata": {},
   "source": [
    "## 역전파 신경망\n",
    "\n",
    "/module/neuralnet_backprop.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d3f195f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        self.y = None\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.forward(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = 1 / (1 + np.exp(-x))\n",
    "        self.y = y\n",
    "        return y\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = dout * self.y * (1 - self.y)\n",
    "        return dx\n",
    "\n",
    "class 완전연결:\n",
    "    def __init__(self, 입력수, 출력수, 활성화=None):\n",
    "        self.W = np.random.randn(입력수, 출력수)\n",
    "        self.b = np.zeros(출력수)\n",
    "        self.activation = 활성화\n",
    "        self.x = None\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.forward(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        z = np.dot(x, self.W) + self.b\n",
    "        if self.activation:\n",
    "            return self.activation(z)\n",
    "        return z\n",
    "\n",
    "    def backward(self, dout):\n",
    "        if self.activation:\n",
    "            dout = self.activation.backward(dout)\n",
    "            \n",
    "        self.dW = np.dot(self.x.T, dout)\n",
    "        # 배치 단위 연산 시, 미분값을 모든 표본에 대해 더합니다.\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        \n",
    "        dx = np.dot(dout, self.W.T)\n",
    "        return dx\n",
    "\n",
    "def softmax(z):\n",
    "    if z.ndim == 1:\n",
    "        z = z.reshape(1, -1)\n",
    "    exp_z = np.exp(z - np.max(z, axis=1).reshape(-1, 1))\n",
    "    return exp_z / np.sum(exp_z, axis=1).reshape(-1, 1)\n",
    "\n",
    "def 교차엔트로피오차(y, y_pred):\n",
    "    delta = 1e-7\n",
    "    배치크기 = y.shape[0]\n",
    "    return -np.sum(y * np.log(y_pred + delta)) / 배치크기\n",
    "\n",
    "class CrossEntropy:\n",
    "    def __init__(self, from_logits=False):\n",
    "        self.y = None\n",
    "        self.from_logits = from_logits\n",
    "        self.proba = None\n",
    "\n",
    "    def __call__(self, z, y):\n",
    "        return self.forward(z, y)\n",
    "\n",
    "    def forward(self, outputs, y):\n",
    "        self.y = y\n",
    "        # z -> softmax -> proba\n",
    "        if not self.from_logits:      \n",
    "            self.proba = outputs\n",
    "        else: # from_logits=True -> 실수값 -> 확률값\n",
    "            self.proba = softmax(outputs)\n",
    "        # CEE(y, proba)\n",
    "        손실 = 교차엔트로피오차(y, self.proba)\n",
    "        return 손실\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        배치크기 = len(self.y)\n",
    "        dz = self.proba - self.y\n",
    "        return dz / 배치크기\n",
    "\n",
    "class 역전파신경망:\n",
    "    def __init__(self, 손실함수):\n",
    "        self.layers = []\n",
    "        self.loss_func = 손실함수\n",
    "\n",
    "    def add(self, layer):\n",
    "        self.layers.append(layer)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        \"\"\"순전파\"\"\"\n",
    "        outputs = x\n",
    "        for layer in self.layers:\n",
    "            outputs = layer(outputs)\n",
    "        return outputs # z_last\n",
    "\n",
    "    def 손실산출(self, x, y):\n",
    "        outputs = self(x)\n",
    "        손실 = self.loss_func(outputs, y)\n",
    "        return 손실\n",
    "\n",
    "    def fit(self, x, y, 배치크기, 에폭수, 학습률):\n",
    "        에폭당_배치수 = len(x) // 배치크기\n",
    "        학습횟수 = 에폭당_배치수 * 에폭수\n",
    "        print(f'배치크기={배치크기}, 에폭수={에폭수}, 학습횟수={학습횟수}({에폭당_배치수}/에폭)')\n",
    "        손실변화 = []\n",
    "        for 학습 in range(학습횟수):\n",
    "            # 1. 미니 배치\n",
    "            표본수 = S = len(x)\n",
    "            배치색인 = np.random.choice(표본수, 배치크기)\n",
    "            x_batch = x[배치색인]\n",
    "            y_batch = y[배치색인]\n",
    "            # 2. 경사 산출 (역전파)\n",
    "            # 1) 순전파\n",
    "            손실 = self.손실산출(x_batch, y_batch)\n",
    "            손실변화.append(손실)\n",
    "            # 2) 역전파            \n",
    "            dout = self.loss_func.backward(1)\n",
    "            for layer in reversed(self.layers):\n",
    "                dout = layer.backward(dout)\n",
    "            # 3. 매개변수 갱신 (경사 하강)\n",
    "            for layer in self.layers:\n",
    "                if isinstance(layer, 완전연결):\n",
    "                    layer.W -= layer.dW * 학습률\n",
    "                    layer.b -= layer.db * 학습률\n",
    "\n",
    "            if 학습 == 0 or (학습 + 1) % 100 == 0:\n",
    "                print(f'[학습 {학습 + 1}] Loss: {손실:.3f}')\n",
    "        return 손실변화\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c84081dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MNIST\n",
    "\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "mnist = {}\n",
    "mnist['train'] = MNIST(root='~/data', train=True, download=True) # ~/의 의미 : 홈 디렉토리 (바인드 되어 있는 이 컴퓨터 디렉토리가 아님.)\n",
    "mnist['test'] = MNIST(root='~/data', train=False, download=True)\n",
    "\n",
    "\n",
    "def 전처리(images):\n",
    "    if not isinstance(images, np.ndarray):\n",
    "        images = images.numpy()\n",
    "    X = images.reshape(-1, 28*28).astype(np.float32) / 255.0    \n",
    "    return X\n",
    "\n",
    "train_data = 전처리(mnist['train'].data)\n",
    "train_target = np.array(mnist['train'].targets)\n",
    "test_data = 전처리(mnist['test'].data)\n",
    "test_target = np.array(mnist['test'].targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bf50a03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치크기=100, 에폭수=10, 학습횟수=6000(600/에폭)\n",
      "[학습 1] Loss: 6.813\n",
      "[학습 100] Loss: 0.878\n",
      "[학습 200] Loss: 0.767\n",
      "[학습 300] Loss: 0.397\n",
      "[학습 400] Loss: 0.885\n",
      "[학습 500] Loss: 0.387\n",
      "[학습 600] Loss: 0.528\n",
      "[학습 700] Loss: 0.292\n",
      "[학습 800] Loss: 0.412\n",
      "[학습 900] Loss: 0.385\n",
      "[학습 1000] Loss: 0.150\n",
      "[학습 1100] Loss: 0.309\n",
      "[학습 1200] Loss: 0.285\n",
      "[학습 1300] Loss: 0.156\n",
      "[학습 1400] Loss: 0.223\n",
      "[학습 1500] Loss: 0.176\n",
      "[학습 1600] Loss: 0.319\n",
      "[학습 1700] Loss: 0.286\n",
      "[학습 1800] Loss: 0.146\n",
      "[학습 1900] Loss: 0.207\n",
      "[학습 2000] Loss: 0.182\n",
      "[학습 2100] Loss: 0.229\n",
      "[학습 2200] Loss: 0.159\n",
      "[학습 2300] Loss: 0.291\n",
      "[학습 2400] Loss: 0.090\n",
      "[학습 2500] Loss: 0.105\n",
      "[학습 2600] Loss: 0.481\n",
      "[학습 2700] Loss: 0.139\n",
      "[학습 2800] Loss: 0.187\n",
      "[학습 2900] Loss: 0.187\n",
      "[학습 3000] Loss: 0.242\n",
      "[학습 3100] Loss: 0.155\n",
      "[학습 3200] Loss: 0.126\n",
      "[학습 3300] Loss: 0.136\n",
      "[학습 3400] Loss: 0.186\n",
      "[학습 3500] Loss: 0.114\n",
      "[학습 3600] Loss: 0.153\n",
      "[학습 3700] Loss: 0.197\n",
      "[학습 3800] Loss: 0.244\n",
      "[학습 3900] Loss: 0.116\n",
      "[학습 4000] Loss: 0.305\n",
      "[학습 4100] Loss: 0.066\n",
      "[학습 4200] Loss: 0.060\n",
      "[학습 4300] Loss: 0.120\n",
      "[학습 4400] Loss: 0.177\n",
      "[학습 4500] Loss: 0.303\n",
      "[학습 4600] Loss: 0.202\n",
      "[학습 4700] Loss: 0.141\n",
      "[학습 4800] Loss: 0.156\n",
      "[학습 4900] Loss: 0.147\n",
      "[학습 5000] Loss: 0.093\n",
      "[학습 5100] Loss: 0.152\n",
      "[학습 5200] Loss: 0.177\n",
      "[학습 5300] Loss: 0.160\n",
      "[학습 5400] Loss: 0.108\n",
      "[학습 5500] Loss: 0.044\n",
      "[학습 5600] Loss: 0.134\n",
      "[학습 5700] Loss: 0.086\n",
      "[학습 5800] Loss: 0.072\n",
      "[학습 5900] Loss: 0.170\n",
      "[학습 6000] Loss: 0.063\n",
      "테스트 손실: 0.195\n",
      "테스트 정확도: 0.939\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "원핫행렬 = np.eye(10)\n",
    "\n",
    "model = 역전파신경망(CrossEntropy(from_logits=True))\n",
    "model.add(완전연결(784, 50, 활성화=Sigmoid()))\n",
    "model.add(완전연결(50, 100, 활성화=Sigmoid()))\n",
    "model.add(완전연결(100, 10, 활성화=None))\n",
    "\n",
    "loss_history = model.fit(train_data, 원핫행렬[train_target], 배치크기=100, 에폭수=10, 학습률=1)\n",
    "\n",
    "# 평가: 테스트 데이터에 대한 성능 측정\n",
    "test_pred_score = model(test_data)\n",
    "test_pred = np.argmax(test_pred_score, axis=1)\n",
    "\n",
    "# 정확도 계산\n",
    "accuracy = np.mean(test_pred == test_target)\n",
    "\n",
    "# 손실값 계산\n",
    "y_onehot = 원핫행렬[test_target]\n",
    "test_loss = model.loss_func(test_pred_score, y_onehot)\n",
    "\n",
    "print(f'테스트 손실: {test_loss:.3f}')\n",
    "print(f'테스트 정확도: {accuracy:.3f}')\n",
    "\n",
    "pd.Series(loss_history).rolling(window=100).mean().plot()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7a9dd4",
   "metadata": {},
   "source": [
    "## PyTorch\n",
    "\n",
    "PyTorch = Numpy + GPU + Back_prop + ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d6616c5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>사과단가</th>\n",
       "      <th>사과수량</th>\n",
       "      <th>부가세</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>순전파</th>\n",
       "      <td>100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>역전파</th>\n",
       "      <td>2.2</td>\n",
       "      <td>110.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      사과단가   사과수량  부가세\n",
       "순전파  100.0    2.0  0.1\n",
       "역전파    2.2  110.0  NaN"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "사과단가 = torch.tensor(100.0, requires_grad=True)\n",
    "사과수량 = torch.tensor(2.0, requires_grad=True)\n",
    "부가세 = torch.tensor(0.1)\n",
    "\n",
    "사과가격 = 사과단가 * 사과수량 * (1 + 부가세)\n",
    "사과가격.backward()\n",
    "\n",
    "pd.DataFrame({\n",
    "    '사과단가': [사과단가.item(), 사과단가.grad.item()],\n",
    "    '사과수량': [사과수량.item(), 사과수량.grad.item()],\n",
    "    '부가세': [부가세.item(), 부가세.grad]\n",
    "    }, index = ['순전파', '역전파'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a899a7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(100., requires_grad=True)\n",
      "100.0\n",
      "tensor(2.2000)\n"
     ]
    }
   ],
   "source": [
    "print(사과단가) # 텐서 객체\n",
    "print(사과단가.item()) # 텐서 객체의 값\n",
    "print(사과단가.grad) # 텐서 객체의 미분값\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986c9c6e",
   "metadata": {},
   "source": [
    "## 파이토치 신경망"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f23b4fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3]) torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "class 다중퍼셉트론:\n",
    "    def __init__(self, 입력수, 출력수, 활성화=None):\n",
    "        self.W = torch.randn(입력수, 출력수, requires_grad=True)\n",
    "        self.b = torch.zeros(출력수, requires_grad=True)\n",
    "        self.활성화 = 활성화\n",
    "\n",
    "    def __call__(self, x):\n",
    "        z = torch.matmul(x, self.W) + self.b\n",
    "        if self.활성화:\n",
    "            return self.활성화(z)\n",
    "        return z\n",
    "\n",
    "layer = 다중퍼셉트론(2, 3, 활성화=torch.sigmoid)\n",
    "print(layer.W.shape, layer.b.shape)\n",
    "assert layer.W.requires_grad and layer.b.requires_grad\n",
    "\n",
    "X = torch.linspace(0, 1, 10).reshape(5, 2)\n",
    "outputs = layer(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0818db8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2]) torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn # 신경망 모듈\n",
    "\n",
    "layer = nn.Linear(in_features=2, out_features=3) # Linear:활성화 함수 없음\n",
    "print(layer.weight.shape, layer.bias.shape)\n",
    "assert layer.weight.requires_grad and layer.bias.requires_grad\n",
    "\n",
    "X = torch.linspace(0, 1, 10).reshape(5, 2)\n",
    "assert torch.allclose(layer(X), torch.matmul(X, layer.weight.T) + layer.bias)\n",
    "\n",
    "# 활성화\n",
    "Z = torch.sigmoid(layer(X)) # 선형 결합 -> 활성화 함수 -> 비선형 결합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1164b722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[에폭 1] 손실: 2.371\n",
      "[에폭 2] 손실: 2.444\n",
      "[에폭 3] 손실: 2.495\n",
      "[에폭 4] 손실: 2.483\n",
      "[에폭 5] 손실: 2.573\n",
      "[에폭 6] 손실: 2.459\n",
      "[에폭 7] 손실: 2.502\n",
      "[에폭 8] 손실: 2.447\n",
      "[에폭 9] 손실: 2.472\n",
      "[에폭 10] 손실: 2.401\n",
      "[에폭 11] 손실: 2.406\n",
      "[에폭 12] 손실: 2.372\n",
      "[에폭 13] 손실: 2.375\n",
      "[에폭 14] 손실: 2.347\n",
      "[에폭 15] 손실: 2.348\n",
      "[에폭 16] 손실: 2.330\n",
      "[에폭 17] 손실: 2.330\n",
      "[에폭 18] 손실: 2.317\n",
      "[에폭 19] 손실: 2.318\n",
      "[에폭 20] 손실: 2.309\n",
      "[에폭 21] 손실: 2.310\n",
      "[에폭 22] 손실: 2.303\n",
      "[에폭 23] 손실: 2.304\n",
      "[에폭 24] 손실: 2.298\n",
      "[에폭 25] 손실: 2.300\n",
      "[에폭 26] 손실: 2.295\n",
      "[에폭 27] 손실: 2.296\n",
      "[에폭 28] 손실: 2.292\n",
      "[에폭 29] 손실: 2.293\n",
      "[에폭 30] 손실: 2.289\n",
      "[에폭 31] 손실: 2.290\n",
      "[에폭 32] 손실: 2.286\n",
      "[에폭 33] 손실: 2.286\n",
      "[에폭 34] 손실: 2.282\n",
      "[에폭 35] 손실: 2.283\n",
      "[에폭 36] 손실: 2.279\n",
      "[에폭 37] 손실: 2.279\n",
      "[에폭 38] 손실: 2.275\n",
      "[에폭 39] 손실: 2.275\n",
      "[에폭 40] 손실: 2.271\n",
      "[에폭 41] 손실: 2.271\n",
      "[에폭 42] 손실: 2.266\n",
      "[에폭 43] 손실: 2.265\n",
      "[에폭 44] 손실: 2.260\n",
      "[에폭 45] 손실: 2.260\n",
      "[에폭 46] 손실: 2.254\n",
      "[에폭 47] 손실: 2.253\n",
      "[에폭 48] 손실: 2.246\n",
      "[에폭 49] 손실: 2.245\n",
      "[에폭 50] 손실: 2.237\n",
      "[에폭 51] 손실: 2.236\n",
      "[에폭 52] 손실: 2.227\n",
      "[에폭 53] 손실: 2.225\n",
      "[에폭 54] 손실: 2.215\n",
      "[에폭 55] 손실: 2.213\n",
      "[에폭 56] 손실: 2.201\n",
      "[에폭 57] 손실: 2.199\n",
      "[에폭 58] 손실: 2.185\n",
      "[에폭 59] 손실: 2.182\n",
      "[에폭 60] 손실: 2.165\n",
      "[에폭 61] 손실: 2.163\n",
      "[에폭 62] 손실: 2.142\n",
      "[에폭 63] 손실: 2.140\n",
      "[에폭 64] 손실: 2.115\n",
      "[에폭 65] 손실: 2.114\n",
      "[에폭 66] 손실: 2.084\n",
      "[에폭 67] 손실: 2.083\n",
      "[에폭 68] 손실: 2.048\n",
      "[에폭 69] 손실: 2.048\n",
      "[에폭 70] 손실: 2.007\n",
      "[에폭 71] 손실: 2.007\n",
      "[에폭 72] 손실: 1.961\n",
      "[에폭 73] 손실: 1.961\n",
      "[에폭 74] 손실: 1.910\n",
      "[에폭 75] 손실: 1.909\n",
      "[에폭 76] 손실: 1.854\n",
      "[에폭 77] 손실: 1.853\n",
      "[에폭 78] 손실: 1.795\n",
      "[에폭 79] 손실: 1.794\n",
      "[에폭 80] 손실: 1.735\n",
      "[에폭 81] 손실: 1.736\n",
      "[에폭 82] 손실: 1.677\n",
      "[에폭 83] 손실: 1.678\n",
      "[에폭 84] 손실: 1.619\n",
      "[에폭 85] 손실: 1.620\n",
      "[에폭 86] 손실: 1.561\n",
      "[에폭 87] 손실: 1.557\n",
      "[에폭 88] 손실: 1.500\n",
      "[에폭 89] 손실: 1.488\n",
      "[에폭 90] 손실: 1.438\n",
      "[에폭 91] 손실: 1.420\n",
      "[에폭 92] 손실: 1.382\n",
      "[에폭 93] 손실: 1.360\n",
      "[에폭 94] 손실: 1.335\n",
      "[에폭 95] 손실: 1.315\n",
      "[에폭 96] 손실: 1.300\n",
      "[에폭 97] 손실: 1.285\n",
      "[에폭 98] 손실: 1.270\n",
      "[에폭 99] 손실: 1.257\n",
      "[에폭 100] 손실: 1.238\n",
      "torch.Size([10000, 10])\n",
      "정확도: 0.5447999835014343\n"
     ]
    }
   ],
   "source": [
    "# 배치가 없는 경우 : 안 좋다. \n",
    "\n",
    "model = nn.Sequential(\n",
    "    #은닉층\n",
    "    nn.Linear(784, 50),\n",
    "    nn.Sigmoid(), # 비선형 활성화\n",
    "    nn.Linear(50, 100),\n",
    "    nn.Sigmoid(),\n",
    "    #출력층\n",
    "    nn.Linear(100, 10),\n",
    "    #nn.Softmax(dim=1) # 출력층 활성화 함수\n",
    ")\n",
    "\n",
    "#학습\n",
    "손실함수 = nn.CrossEntropyLoss() # 로짓값을 입력으로 받음, 정답은 정수값 (원핫인코딩을 하지 않음)\n",
    "학습률 = 1.0\n",
    "학습횟수 = 100\n",
    "\n",
    "train_data = mnist['train'].data.reshape(-1, 784).float()/255.0\n",
    "train_target = mnist['train'].targets\n",
    "for 학습 in range(학습횟수):\n",
    "    outputs = model(train_data)\n",
    "    손실 = 손실함수(outputs, train_target)\n",
    "    print(f'[에폭 {학습 + 1}] 손실: {손실.item():.3f}')\n",
    "    손실변화 = []\n",
    "    손실변화.append(손실.item())\n",
    "    #print(f'손실: {손실.item():.3f}')\n",
    "\n",
    "    # 손실의 type\n",
    "    #print(f'손실의 type: {type(손실)}')\n",
    "\n",
    "    #역전파\n",
    "    손실.backward()\n",
    "    #매개변수 갱신\n",
    "    with torch.no_grad(): # 이 코드의 의미 : 이 코드 안에서는 기울기를 계산하지 않음\n",
    "        for param in model.parameters():\n",
    "            param -= 학습률 * param.grad # 더하는 것이 아니라 빼는 이유 : 기울기가 양수일 때, 값이 줄어들기 때문\n",
    "        model.zero_grad() # 기울기 초기화 이유 : 여러 번 반복 학습할 때, 기울기가 누적되기 때문\n",
    "\n",
    "# 평가\n",
    "test_data = mnist['test'].data.reshape(-1, 784).float()/255.0\n",
    "outputs = model(test_data)\n",
    "print(outputs.shape)\n",
    "y_pred = torch.argmax(outputs, dim=1)\n",
    "print(f'정확도: {torch.sum(y_pred == test_target) / len(test_target)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fd842f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(784, 50),\n",
    "        nn.Sigmoid(),\n",
    "        nn.Linear(50, 100),\n",
    "        nn.Sigmoid(),\n",
    "        nn.Linear(100, 10),\n",
    "    )\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3e9b01",
   "metadata": {},
   "source": [
    "## 배치 크기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "d043fc75",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but got mat1 is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA_addmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[238], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m train_target \u001b[38;5;241m=\u001b[39m mnist[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtargets\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# 처음 시작 시, \"워밍 업\" 단계\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m 배치크기 \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m1000\u001b[39m, \u001b[38;5;241m6000\u001b[39m, \u001b[38;5;28mlen\u001b[39m(train_data)]:\n\u001b[1;32m     15\u001b[0m     배치색인 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandperm(\u001b[38;5;28mlen\u001b[39m(train_data))[:배치크기]\n",
      "File \u001b[0;32m~/.conda/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.conda/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;124;03mRuns the forward pass.\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.conda/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/linear.py:134\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    131\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m    Runs the forward pass.\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but got mat1 is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA_addmm)"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "model = build_model() # 신경망 모델 생성 (초기화)\n",
    "손실함수 = nn.CrossEntropyLoss() # 손실 함수 생성\n",
    "result = {}\n",
    "학습률 = 1.0\n",
    "학습횟수 = 100\n",
    "train_data = mnist['train'].data.reshape(-1, 784).float()/255.0\n",
    "train_target = mnist['train'].targets\n",
    "\n",
    "# 처음 시작 시, \"워밍 업\" 단계\n",
    "_ = model(train_data)\n",
    "\n",
    "for 배치크기 in [1, 10, 100, 1000, 6000, len(train_data)]:\n",
    "    배치색인 = torch.randperm(len(train_data))[:배치크기]\n",
    "    소요시간 = []\n",
    "    for __ in range(5): # 5회 반복 후 평균 시간 측정\n",
    "        start = time.time()\n",
    "        outputs = model(train_data[배치색인])\n",
    "        손실 = 손실함수(outputs, train_target[배치색인])\n",
    "        end = time.time()\n",
    "        소요시간.append(end - start)\n",
    "    result[배치크기] = {'손실': 손실.item(), '소요시간ms': np.mean(소요시간)*1000}\n",
    "\n",
    "\n",
    "pd.DataFrame(result).round(3).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7946c5f",
   "metadata": {},
   "source": [
    "## 배치 크기\n",
    "\n",
    "원래보다 작은 크기로도 전체 손실 추정이 가능할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "15e04a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "W1 = next(model.parameters()) # 코드의 의미 : 첫 번째 매개변수를 가져옴\n",
    "print(W1.device) # 텐서가 저장된 장치 확인\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "model.to(device)\n",
    "W1 = W1.to(device)\n",
    "print(W1.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "c61eb189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치크기=600, 에폭수=60, 학습횟수=6000(100/에폭)\n",
      "1 에폭 // 소요시간: 0.455초, 손실: 1.291\n",
      "2 에폭 // 소요시간: 0.403초, 손실: 0.597\n",
      "3 에폭 // 소요시간: 0.409초, 손실: 0.439\n",
      "4 에폭 // 소요시간: 0.424초, 손실: 0.318\n",
      "5 에폭 // 소요시간: 0.394초, 손실: 0.260\n",
      "6 에폭 // 소요시간: 0.384초, 손실: 0.271\n",
      "7 에폭 // 소요시간: 0.513초, 손실: 0.257\n",
      "8 에폭 // 소요시간: 0.363초, 손실: 0.217\n",
      "9 에폭 // 소요시간: 0.387초, 손실: 0.149\n",
      "10 에폭 // 소요시간: 0.369초, 손실: 0.173\n",
      "11 에폭 // 소요시간: 0.355초, 손실: 0.184\n",
      "12 에폭 // 소요시간: 0.406초, 손실: 0.114\n",
      "13 에폭 // 소요시간: 0.366초, 손실: 0.163\n",
      "14 에폭 // 소요시간: 0.369초, 손실: 0.141\n",
      "15 에폭 // 소요시간: 0.353초, 손실: 0.185\n",
      "16 에폭 // 소요시간: 0.342초, 손실: 0.162\n",
      "17 에폭 // 소요시간: 0.374초, 손실: 0.121\n",
      "18 에폭 // 소요시간: 0.381초, 손실: 0.091\n",
      "19 에폭 // 소요시간: 0.359초, 손실: 0.111\n",
      "20 에폭 // 소요시간: 0.399초, 손실: 0.089\n",
      "21 에폭 // 소요시간: 0.351초, 손실: 0.151\n",
      "22 에폭 // 소요시간: 0.364초, 손실: 0.078\n",
      "23 에폭 // 소요시간: 0.342초, 손실: 0.092\n",
      "24 에폭 // 소요시간: 0.374초, 손실: 0.102\n",
      "25 에폭 // 소요시간: 0.417초, 손실: 0.104\n",
      "26 에폭 // 소요시간: 0.392초, 손실: 0.103\n",
      "27 에폭 // 소요시간: 0.368초, 손실: 0.137\n",
      "28 에폭 // 소요시간: 0.356초, 손실: 0.094\n",
      "29 에폭 // 소요시간: 0.415초, 손실: 0.093\n",
      "30 에폭 // 소요시간: 0.360초, 손실: 0.062\n",
      "31 에폭 // 소요시간: 0.363초, 손실: 0.077\n",
      "32 에폭 // 소요시간: 0.397초, 손실: 0.081\n",
      "33 에폭 // 소요시간: 0.436초, 손실: 0.080\n",
      "34 에폭 // 소요시간: 0.377초, 손실: 0.077\n",
      "35 에폭 // 소요시간: 0.348초, 손실: 0.080\n",
      "36 에폭 // 소요시간: 0.369초, 손실: 0.070\n",
      "37 에폭 // 소요시간: 0.346초, 손실: 0.072\n",
      "38 에폭 // 소요시간: 0.338초, 손실: 0.043\n",
      "39 에폭 // 소요시간: 0.361초, 손실: 0.056\n",
      "40 에폭 // 소요시간: 0.479초, 손실: 0.052\n",
      "41 에폭 // 소요시간: 0.386초, 손실: 0.038\n",
      "42 에폭 // 소요시간: 0.340초, 손실: 0.039\n",
      "43 에폭 // 소요시간: 0.344초, 손실: 0.058\n",
      "44 에폭 // 소요시간: 0.354초, 손실: 0.036\n",
      "45 에폭 // 소요시간: 0.364초, 손실: 0.078\n",
      "46 에폭 // 소요시간: 0.369초, 손실: 0.045\n",
      "47 에폭 // 소요시간: 0.424초, 손실: 0.058\n",
      "48 에폭 // 소요시간: 0.362초, 손실: 0.038\n",
      "49 에폭 // 소요시간: 0.391초, 손실: 0.054\n",
      "50 에폭 // 소요시간: 0.367초, 손실: 0.041\n",
      "51 에폭 // 소요시간: 0.359초, 손실: 0.035\n",
      "52 에폭 // 소요시간: 0.378초, 손실: 0.035\n",
      "53 에폭 // 소요시간: 0.352초, 손실: 0.047\n",
      "54 에폭 // 소요시간: 0.370초, 손실: 0.034\n",
      "55 에폭 // 소요시간: 0.437초, 손실: 0.031\n",
      "56 에폭 // 소요시간: 0.401초, 손실: 0.033\n",
      "57 에폭 // 소요시간: 0.402초, 손실: 0.031\n",
      "58 에폭 // 소요시간: 0.401초, 손실: 0.048\n",
      "59 에폭 // 소요시간: 0.399초, 손실: 0.022\n",
      "60 에폭 // 소요시간: 0.357초, 손실: 0.032\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "model = build_model() # 신경망 모델 생성 (초기화)\n",
    "손실함수 = nn.CrossEntropyLoss() # 손실 함수 생성\n",
    "최적화 = torch.optim.SGD(model.parameters(), lr=1.0)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "에폭수 = 60\n",
    "배치크기 = 600\n",
    "에폭당_배치수 = len(train_data) // 배치크기\n",
    "학습횟수 = 에폭당_배치수 * 에폭수\n",
    "print(f'배치크기={배치크기}, 에폭수={에폭수}, 학습횟수={학습횟수}({에폭당_배치수}/에폭)')\n",
    "\n",
    "손실변화 = []\n",
    "에폭당_소요시간 = []\n",
    "for 에폭 in range(에폭수):\n",
    "    start = time.time()\n",
    "    for __ in range(에폭당_배치수):        \n",
    "        배치색인 = torch.randperm(len(train_data))[:배치크기]\n",
    "        # 전체 데이터가 아닌 배치 데이터와 타겟을 GPU로 보냄\n",
    "        batch_data = train_data[배치색인].to(device)\n",
    "        batch_target = train_target[배치색인].to(device)\n",
    "        #print(batch_data.shape, batch_target.shape)\n",
    "\n",
    "        #순전파\n",
    "        loss = 손실함수(model(batch_data), batch_target)\n",
    "        손실변화.append(loss.item())       \n",
    "\n",
    "        #역전파\n",
    "        loss.backward()\n",
    "\n",
    "        #매개변수 갱신\n",
    "        최적화.step()\n",
    "        최적화.zero_grad()\n",
    "\n",
    "    end = time.time()\n",
    "    에폭당_소요시간.append(end - start)\n",
    "    print(f'{에폭 + 1} 에폭 // 소요시간: {에폭당_소요시간[-1]:.3f}초, 손실: {손실변화[-1]:.3f}')\n",
    "\n",
    "# 평가\n",
    "# test_data_device = test_data.to(device)\n",
    "# test_target_device = test_target.to(device)\n",
    "# outputs = model(test_data_device)\n",
    "# y_pred = torch.argmax(outputs, dim=1)\n",
    "# print(f'정확도: {torch.sum(y_pred == test_target_device) / len(test_target_device)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab1a69f",
   "metadata": {},
   "source": [
    "## 5일차 오전 종료"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458e8235",
   "metadata": {},
   "source": [
    "## Keras\n",
    "\n",
    "신경망 구성/실험을 위한 고수준 API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "edaecc31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.9.0+cu128\n",
      "Keras version: 3.12.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'torch'\n",
    "\n",
    "import torch\n",
    "import keras\n",
    "\n",
    "print('PyTorch version:', torch.__version__)\n",
    "print('Keras version:', keras.__version__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "abc68a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">39,250</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │        \u001b[38;5;34m39,250\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │         \u001b[38;5;34m5,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_20 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,010\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">45,360</span> (177.19 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m45,360\u001b[0m (177.19 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">45,360</span> (177.19 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m45,360\u001b[0m (177.19 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - accuracy: 0.8035 - loss: 0.6055\n",
      "Epoch 2/10\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - accuracy: 0.9339 - loss: 0.2226\n",
      "Epoch 3/10\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - accuracy: 0.9518 - loss: 0.1622\n",
      "Epoch 4/10\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9611 - loss: 0.1290\n",
      "Epoch 5/10\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.9677 - loss: 0.1080\n",
      "Epoch 6/10\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9725 - loss: 0.0922\n",
      "Epoch 7/10\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.9751 - loss: 0.0818\n",
      "Epoch 8/10\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9776 - loss: 0.0734\n",
      "Epoch 9/10\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.9799 - loss: 0.0659\n",
      "Epoch 10/10\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9815 - loss: 0.0602\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.Input(shape=(784,)),\n",
    "    layers.Dense(units=50,  activation='sigmoid'), # nn.Linear + nn.Sigmoid\n",
    "    layers.Dense(units=100, activation='sigmoid'),\n",
    "    layers.Dense(units=10) # softmax를 안하면, from_logits=True로 설정해야 함\n",
    "])\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), # 다중 분류 손실\n",
    "    optimizer=keras.optimizers.SGD(learning_rate=1.0),\n",
    "    metrics=['accuracy'] # 평가지표 : 정확도\n",
    ") # 손실함수와 최적화 기법을 지정\n",
    "\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    train_target,\n",
    "    epochs=10,\n",
    "    batch_size=100,\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18523ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda? True\n",
      "<class 'torch.Tensor'> torch.Size([10000, 10]) cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Keras 연산은 설정된 백엔드 (여기서는 PyTorch)를 사용합니다. \n",
    "# GPU가 가능한 경우, 자동으로 GPU를 사용합니다. \n",
    "print('Cuda?', torch.cuda.is_available())\n",
    "outputs = model(test_data)\n",
    "print(type(outputs), outputs.shape, outputs.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0871f692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0140"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9718 - loss: 0.0909\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Loss        0.090852\n",
       "Accuracy    0.971800\n",
       "dtype: float64"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 기본 배치 크기 : 32, 여기서도 배치로 계산하는 것이 좋다. \n",
    "test_loss, *metrics = model.evaluate(test_data, test_target)\n",
    "\n",
    "pd.Series({'Loss': test_loss, 'Accuracy': metrics[0]})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3498177e",
   "metadata": {},
   "source": [
    "## Fashion MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "9a30b7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28]) torch.Size([60000])\n",
      "torch.Size([10000, 28, 28]) torch.Size([10000])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>6000</td>\n",
       "      <td>6000</td>\n",
       "      <td>6000</td>\n",
       "      <td>6000</td>\n",
       "      <td>6000</td>\n",
       "      <td>6000</td>\n",
       "      <td>6000</td>\n",
       "      <td>6000</td>\n",
       "      <td>6000</td>\n",
       "      <td>6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0     1     2     3     4     5     6     7     8     9\n",
       "train  6000  6000  6000  6000  6000  6000  6000  6000  6000  6000\n",
       "test   1000  1000  1000  1000  1000  1000  1000  1000  1000  1000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['T-shirt/top',\n",
       " 'Trouser',\n",
       " 'Pullover',\n",
       " 'Dress',\n",
       " 'Coat',\n",
       " 'Sandal',\n",
       " 'Shirt',\n",
       " 'Sneaker',\n",
       " 'Bag',\n",
       " 'Ankle boot']"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaEAAAGdCAYAAAC7EMwUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/TGe4hAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAhPklEQVR4nO3df3DU9b3v8dfm1xJwsxgh2URiTFuoChxaFflxkF9Xc0inXBV7LmpvD8xtHa3ADAcdW8o5I6dzhzh25HLnUumtp5fCVCpz5vrrFK4aDybIobSIeOWgw4klSCxJIxF2Q0g22eRz/+CSGkHM++uGT348HzM7Y3a/L78fvnyTV77s7ntDzjknAAA8yPC9AADA8EUJAQC8oYQAAN5QQgAAbyghAIA3lBAAwBtKCADgDSUEAPAmy/cCPq27u1snTpxQJBJRKBTyvRwAgJFzTi0tLSouLlZGxqWvdQZcCZ04cUIlJSW+lwEA+ILq6+s1bty4S24z4EooEolIkmbpG8pStufVAACsUurUHu3s+Xl+Kf1WQk899ZR+8pOfqKGhQRMnTtSGDRt06623fm7u/D/BZSlbWSFKCAAGnf8/kbQvT6n0ywsTtm/frpUrV2rNmjU6ePCgbr31VlVUVOj48eP9sTsAwCDVLyW0fv16ffe739X3vvc9XX/99dqwYYNKSkq0adOm/tgdAGCQSnsJdXR06MCBAyovL+91f3l5ufbu3XvB9slkUolEotcNADA8pL2ETp48qa6uLhUWFva6v7CwUI2NjRdsX1lZqWg02nPjlXEAMHz025tVP/2ElHPuok9SrV69WvF4vOdWX1/fX0sCAAwwaX913JgxY5SZmXnBVU9TU9MFV0eSFA6HFQ6H070MAMAgkPYroZycHN10002qqqrqdX9VVZVmzpyZ7t0BAAaxfnmf0KpVq/Sd73xHN998s2bMmKGf//znOn78uB588MH+2B0AYJDqlxJavHixmpub9eMf/1gNDQ2aNGmSdu7cqdLS0v7YHQBgkAo555zvRXxSIpFQNBrVXN3BxAQAGIRSrlPVelHxeFx5eXmX3JaPcgAAeEMJAQC8oYQAAN5QQgAAbyghAIA3lBAAwBtKCADgDSUEAPCGEgIAeEMJAQC8oYQAAN5QQgAAbyghAIA3lBAAwBtKCADgDSUEAPCGEgIAeEMJAQC8oYQAAN5QQgAAbyghAIA3lBAAwBtKCADgDSUEAPCGEgIAeEMJAQC8yfK9AGBACYXsGefSv46LyLwq35w59VcTAu0rb9u+QDmzAMc7lJVtzrjODnNmwAtyrgbVj+c4V0IAAG8oIQCAN5QQAMAbSggA4A0lBADwhhICAHhDCQEAvKGEAADeUEIAAG8oIQCAN5QQAMAbSggA4A0DTIFPCGVmmjMulTJnMr52gznz3gNX2PfTZo5IkrJbbzFnstq67ft59U1z5rIOIw0yYDXAOaSQ/Xrgch6HUJatKkLOSX38tuBKCADgDSUEAPCGEgIAeEMJAQC8oYQAAN5QQgAAbyghAIA3lBAAwBtKCADgDSUEAPCGEgIAeEMJAQC8YYAp8AnWQY1SsAGm9X812pz59ow3zJl//ehL5owkfRCOmTMu176frNtmmDMTnvqjOZM6dtyckSQ5Z48EOB+CyLzyymDBri57JJEwbe9c348BV0IAAG8oIQCAN2kvobVr1yoUCvW6xWL2S3sAwNDXL88JTZw4Ua+99lrP15lBPuQJADDk9UsJZWVlcfUDAPhc/fKcUG1trYqLi1VWVqZ77rlHR48e/cxtk8mkEolErxsAYHhIewlNmzZNW7du1SuvvKKnn35ajY2Nmjlzppqbmy+6fWVlpaLRaM+tpKQk3UsCAAxQaS+hiooK3X333Zo8ebJuu+027dixQ5K0ZcuWi26/evVqxePxnlt9fX26lwQAGKD6/c2qo0aN0uTJk1VbW3vRx8PhsMLhcH8vAwAwAPX7+4SSyaTee+89FRUV9feuAACDTNpL6JFHHlFNTY3q6ur0u9/9Tt/61reUSCS0ZMmSdO8KADDIpf2f4z788EPde++9OnnypMaOHavp06dr3759Ki0tTfeuAACDXNpL6Nlnn033/xK4bLrb2y/Lfjq+fsac+Vb0TXNmREanOSNJNRnd5swfd9lf2dr1F/bj8MH6iDnTfXCmOSNJV/2bfdhn3sEGc+bk7KvNmY9usg9XlaTCffbMla/9wbS96+6QTvZtW2bHAQC8oYQAAN5QQgAAbyghAIA3lBAAwBtKCADgDSUEAPCGEgIAeEMJAQC8oYQAAN5QQgAAbyghAIA3/f6hdoAXoVCwnLMPhTzzn6abM39zQ7U584fOsebMuJyPzRlJ+uviA/bQf7ZnNh6ZY860Ho2aMxmjgg37bJxu/z39j3fY/55cZ8qcufKtYD++M5b8yZxJdHzJtH2qs116sY/rMa8GAIA0oYQAAN5QQgAAbyghAIA3lBAAwBtKCADgDSUEAPCGEgIAeEMJAQC8oYQAAN5QQgAAbyghAIA3lBAAwBumaOPyCjrdegCb/oPfmzPzrni3H1ZyoasVbHp0q8sxZ053jTJnHrthhznz0YSIOdPpgv2o+8famebMmQBTvjNT9u+L6f/loDkjSXfn7zdnnvjfk03bp1xnn7flSggA4A0lBADwhhICAHhDCQEAvKGEAADeUEIAAG8oIQCAN5QQAMAbSggA4A0lBADwhhICAHhDCQEAvGGAKS4vF2yg5kBWe6bAnGnOu8KcaUyNNmeuyjxjzkhSJKPNnLk2+6Q581GXfRhpZna3OdPhMs0ZSfqHif9szrRfn23OZIe6zJmZI06YM5L01+/+jTkzSkcD7asvuBICAHhDCQEAvKGEAADeUEIAAG8oIQCAN5QQAMAbSggA4A0lBADwhhICAHhDCQEAvKGEAADeUEIAAG8YYAp8QWPD9iGhI0Kd5kxOKGXOnOi80pyRpNq2r5oz/56wD3JdUHjYnOkMMIw0U8EG5wYZLFqcfcqcaXf2oaf2M+icvyy0DyN9O+C++oIrIQCAN5QQAMAbcwnt3r1bCxcuVHFxsUKhkF544YVejzvntHbtWhUXFys3N1dz587V4cP2S24AwNBnLqHW1lZNmTJFGzduvOjjTzzxhNavX6+NGzdq//79isViuv3229XS0vKFFwsAGFrML0yoqKhQRUXFRR9zzmnDhg1as2aNFi1aJEnasmWLCgsLtW3bNj3wwANfbLUAgCElrc8J1dXVqbGxUeXl5T33hcNhzZkzR3v37r1oJplMKpFI9LoBAIaHtJZQY2OjJKmwsLDX/YWFhT2PfVplZaWi0WjPraSkJJ1LAgAMYP3y6rhQKNTra+fcBfedt3r1asXj8Z5bfX19fywJADAApfXNqrFYTNK5K6KioqKe+5uami64OjovHA4rHA6ncxkAgEEirVdCZWVlisViqqqq6rmvo6NDNTU1mjlzZjp3BQAYAsxXQmfOnNH777/f83VdXZ3efvtt5efn65prrtHKlSu1bt06jR8/XuPHj9e6des0cuRI3XfffWldOABg8DOX0Jtvvql58+b1fL1q1SpJ0pIlS/TLX/5Sjz76qNra2vTQQw/p1KlTmjZtml599VVFIpH0rRoAMCSEnHPBJvv1k0QioWg0qrm6Q1kh+1A/DHCf8QKVS0Yy7QMrXco+7FOSMq+0D/y857eH7PsJ2b/tPkrZf5EbnXnWnJGkmtP2AaaHm2PmzI+/+pI589bZa82Z4hz7UFEp2PE71jHGnBkfvvirhy/l/5yaYs5IUsmIj82ZV1fONm2fSrVrT/U/KB6PKy8v75LbMjsOAOANJQQA8IYSAgB4QwkBALyhhAAA3lBCAABvKCEAgDeUEADAG0oIAOANJQQA8IYSAgB4QwkBALyhhAAA3qT1k1WBzxVgaHsoy36aBp2iXf/d682Z+SP/2ZzZ2361OTM2q8Wc6XT2CeSSVBSOmzORwnZz5nTXSHMmP+uMOdPSlWvOSNLIjKQ5E+Tv6cack+bM3752ozkjSZFJzeZMXrbteqXbcH3DlRAAwBtKCADgDSUEAPCGEgIAeEMJAQC8oYQAAN5QQgAAbyghAIA3lBAAwBtKCADgDSUEAPCGEgIAeMMAU1xWoewcc6a73T4YM6gxhzrMmZNd2ebM6Iyz5kxOqMuc6Qg4wHRmfp0581GAIaFvtZWZM5HMNnNmbIZ9qKgklWTbh30eai8xZ3a2fsWc+e43XzNnJOnXP7/dnMl5ea9p+wzX2fdtrYsBACBdKCEAgDeUEADAG0oIAOANJQQA8IYSAgB4QwkBALyhhAAA3lBCAABvKCEAgDeUEADAG0oIAODN8B5gGgoFi2XZB1aGMgP0fYY9092etO+n2z4YMyjXaR8Qejn99/+50ZypT402Zxo77ZnRmfahp10Kdo7va4uaMyMy+j608ryxWQlzJtFtH5QaVEv3CHOmM8DQ2CDH7gdX1ZozkvRc/LZAuf7ClRAAwBtKCADgDSUEAPCGEgIAeEMJAQC8oYQAAN5QQgAAbyghAIA3lBAAwBtKCADgDSUEAPCGEgIAeDNkBpiGsux/FJdKBdpXkCGczj6fcEhqu+MWc6b+TvuA1W9//ffmjCQ1piLmzMGz15oz0cw2c2ZUhn04bbuzD9uVpBMdV5ozQYZw5medMWcKAgw97XLBft/+Y6f9OAQRZDjthyn7sZOklv/YYs6M3hpoV33ClRAAwBtKCADgjbmEdu/erYULF6q4uFihUEgvvPBCr8eXLl2qUCjU6zZ9+vR0rRcAMISYS6i1tVVTpkzRxo2f/eFfCxYsUENDQ89t586dX2iRAIChyfxsfkVFhSoqKi65TTgcViwWC7woAMDw0C/PCVVXV6ugoEATJkzQ/fffr6amps/cNplMKpFI9LoBAIaHtJdQRUWFnnnmGe3atUtPPvmk9u/fr/nz5yuZvPjLSysrKxWNRntuJSUl6V4SAGCASvv7hBYvXtzz35MmTdLNN9+s0tJS7dixQ4sWLbpg+9WrV2vVqlU9XycSCYoIAIaJfn+zalFRkUpLS1VbW3vRx8PhsMLhcH8vAwAwAPX7+4Sam5tVX1+voqKi/t4VAGCQMV8JnTlzRu+//37P13V1dXr77beVn5+v/Px8rV27VnfffbeKiop07Ngx/ehHP9KYMWN01113pXXhAIDBz1xCb775pubNm9fz9fnnc5YsWaJNmzbp0KFD2rp1q06fPq2ioiLNmzdP27dvVyRin8kFABjaQs4553sRn5RIJBSNRjVXdygrFGz44kCUVWR/31RnWaE58/H1I82Zs7GQOSNJX/vGe+bM0sI95sxHXXnmTHYo2HDalq5ccyaWfdqc2RW/wZy5Iss+wDTIoFRJujH3mDlzutt+7hVnnTJnfvD+t8yZwpH2oZ2S9I+l9jfad7puc+ZIp/158UiGfZCyJL1x9ivmzPM3jDVtn3KdqtaLisfjysu79Pcvs+MAAN5QQgAAbyghAIA3lBAAwBtKCADgDSUEAPCGEgIAeEMJAQC8oYQAAN5QQgAAbyghAIA3lBAAwBtKCADgTb9/surlkqyYas4UrDkaaF9fy/vQnLkh1z49ur3bPkV8REanOfNu29XmjCSd7c4xZ2o77NPE4yn7dObMkH2SsSQ1ddg/cuTJutvMmX+55WfmzN+dWGDOZOQGG5Lf3HWFOXP3FYkAe7Kf4w9cs9uc+VJOkzkjSb9ptX8Y54nOK82Zwuy4OXNt9kfmjCQtivy7OfO8bFO0LbgSAgB4QwkBALyhhAAA3lBCAABvKCEAgDeUEADAG0oIAOANJQQA8IYSAgB4QwkBALyhhAAA3lBCAABvBuwA01BWlkKhvi9v2rr95n38h8hhc0aSzrqwORNkGGmQQYhBRLPOBsolO+2nT1NnXqB9WU0INwbK3ZX3tjmze+M0c2ZW+wpz5g/zN5sz/9KWac5I0kcp+9/TPXXzzZm3jpeYM9OvrTNnJkf+aM5IwYbnRjLbzZnsUMqcae22/xySpH3t9uG0/YkrIQCAN5QQAMAbSggA4A0lBADwhhICAHhDCQEAvKGEAADeUEIAAG8oIQCAN5QQAMAbSggA4A0lBADwZsAOMG34/k3KDI/o8/Zro//DvI9tH083ZySpZMTH5kxpzklzZkruB+ZMEJEM+8BFSfpqnn3o4m9ax5kz1aevM2eKsk+bM5L0xtkvmzPPrv2JObP0bx82Z2bsfNCcSVwb7PfM1ChnzuRNaTZn/u7rO8yZnFCXOXO6yz6IVJLyw63mzOjMYAOBrYIMUpakSEabOZP51a+YtnddSam2b9tyJQQA8IYSAgB4QwkBALyhhAAA3lBCAABvKCEAgDeUEADAG0oIAOANJQQA8IYSAgB4QwkBALyhhAAA3gzYAaYjm7qVmdPd5+1/k/iaeR9fyv3InJGkk50Rc+aVM5PNmXG5p8yZaKZ9OOFXwo3mjCS93T7anHn5o4nmTHFuwpz5U2fUnJGk5s5R5szZbvsgyV/8t/XmzJN/us2cuSv/LXNGkqbk2IeRnu62/077bkfMnGnp7vtg4/PaXbY5I0nxAINPIwG+Bzud/Udxpuv7z8dPGp1hH7CamHyVaftUZzsDTAEAAx8lBADwxlRClZWVmjp1qiKRiAoKCnTnnXfqyJEjvbZxzmnt2rUqLi5Wbm6u5s6dq8OHD6d10QCAocFUQjU1NVq2bJn27dunqqoqpVIplZeXq7X1zx/89MQTT2j9+vXauHGj9u/fr1gspttvv10tLS1pXzwAYHAzPRv28ssv9/p68+bNKigo0IEDBzR79mw557RhwwatWbNGixYtkiRt2bJFhYWF2rZtmx544IH0rRwAMOh9oeeE4vG4JCk/P1+SVFdXp8bGRpWXl/dsEw6HNWfOHO3du/ei/49kMqlEItHrBgAYHgKXkHNOq1at0qxZszRp0iRJUmPjuZf6FhYW9tq2sLCw57FPq6ysVDQa7bmVlJQEXRIAYJAJXELLly/XO++8o1//+tcXPBYKhXp97Zy74L7zVq9erXg83nOrr68PuiQAwCAT6M2qK1as0EsvvaTdu3dr3LhxPffHYufeeNbY2KiioqKe+5uami64OjovHA4rHLa/2Q8AMPiZroScc1q+fLmee+457dq1S2VlZb0eLysrUywWU1VVVc99HR0dqqmp0cyZM9OzYgDAkGG6Elq2bJm2bdumF198UZFIpOd5nmg0qtzcXIVCIa1cuVLr1q3T+PHjNX78eK1bt04jR47Ufffd1y9/AADA4GUqoU2bNkmS5s6d2+v+zZs3a+nSpZKkRx99VG1tbXrooYd06tQpTZs2Ta+++qoiEfu8NQDA0BZyzjnfi/ikRCKhaDSq2bP+XllZfR9UOHXDAfO+/i1RbM5IUuEI+xtv/+KKD82ZI2ftwx1PtOWZMyOzOs0ZScrNtOdSzv5amIKw/XhfE7YP4JSkSIZ9+GROqMuc6QrwmqCJOSfMmeOpK80ZSWpMjTZn3j1r/366Mss+TPNQgO/bs6kcc0aSkl32p83bU/ZMNNxuzkzN/8CckaQM2X/kb3tpjmn77vZ2Hf2vaxSPx5WXd+mfScyOAwB4QwkBALyhhAAA3lBCAABvKCEAgDeUEADAG0oIAOANJQQA8IYSAgB4QwkBALyhhAAA3lBCAABvKCEAgDeBPln1csjY844yQtl93v6fXv1L8z7+/o5/Mmckqeb0debMbxonmzOJDvsnzo4d2WrO5GXbp1RLUn62fV/RAFOTR4RS5syp1ChzRpKSGX0/587r0sU/uv5SGpNRc+Zfu8ebM53dmeaMJCUD5IJMVf+4Y4w5U5wbN2daUn2fyP9Jx1ryzZmT8SvMmfaR9h/Fe7q+bM5I0oLYYXMmt8l2jncl+749V0IAAG8oIQCAN5QQAMAbSggA4A0lBADwhhICAHhDCQEAvKGEAADeUEIAAG8oIQCAN5QQAMAbSggA4E3IOed8L+KTEomEotGo5uoOZRkGmAYR//b0QLkvPXTEnLlldJ0581biGnPmeICBi53dwX4Xyc7oNmdGZneYMyMCDMbMyewyZyQpQ/Zvh+4AA0xHZdqPw6ispDmTl9VuzkhSJNOeywjZz4cgMgP8Hf0+fm36F/IZIgH+nlLO/j04I/oHc0aS/lfdTHMm+o33TdunXKeq9aLi8bjy8vIuuS1XQgAAbyghAIA3lBAAwBtKCADgDSUEAPCGEgIAeEMJAQC8oYQAAN5QQgAAbyghAIA3lBAAwBtKCADgzcAdYJqxyDbAtDvYwMrLpfXuaebMtB/tt2ci9qGG1+X8yZyRpGzZB1aOCDDkclSGfUBoe8DTOshvZXvaSsyZrgB72nXqenOmM8BgTEn609lLD528mOyAQ2Otup39fGhLBRuGHG8bYc5kZtjPvfbqMebMVe/aB/tKUnin/eeKFQNMAQCDAiUEAPCGEgIAeEMJAQC8oYQAAN5QQgAAbyghAIA3lBAAwBtKCADgDSUEAPCGEgIAeEMJAQC8GbgDTHWHbYApAgtNnRwo1xbLNWfCzUlzpqXUvp+8P7SaM5KUkUyZM93/971A+wKGKgaYAgAGBUoIAOCNqYQqKys1depURSIRFRQU6M4779SRI0d6bbN06VKFQqFet+nTp6d10QCAocFUQjU1NVq2bJn27dunqqoqpVIplZeXq7W197+/L1iwQA0NDT23nTt3pnXRAIChIcuy8csvv9zr682bN6ugoEAHDhzQ7Nmze+4Ph8OKxWLpWSEAYMj6Qs8JxeNxSVJ+fn6v+6urq1VQUKAJEybo/vvvV1NT02f+P5LJpBKJRK8bAGB4CFxCzjmtWrVKs2bN0qRJk3rur6io0DPPPKNdu3bpySef1P79+zV//nwlkxd/aW5lZaWi0WjPraSkJOiSAACDTOD3CS1btkw7duzQnj17NG7cuM/crqGhQaWlpXr22We1aNGiCx5PJpO9CiqRSKikpIT3CV1GvE/oz3ifEPDFWd4nZHpO6LwVK1bopZde0u7duy9ZQJJUVFSk0tJS1dbWXvTxcDiscDgcZBkAgEHOVELOOa1YsULPP/+8qqurVVZW9rmZ5uZm1dfXq6ioKPAiAQBDk+k5oWXLlulXv/qVtm3bpkgkosbGRjU2NqqtrU2SdObMGT3yyCP67W9/q2PHjqm6uloLFy7UmDFjdNddd/XLHwAAMHiZroQ2bdokSZo7d26v+zdv3qylS5cqMzNThw4d0tatW3X69GkVFRVp3rx52r59uyKRSNoWDQAYGsz/HHcpubm5euWVV77QggAAw0egFyZgaHH7DwXKjUjzOj5L3t7LtCNJ3ZdvVwDEAFMAgEeUEADAG0oIAOANJQQA8IYSAgB4QwkBALyhhAAA3lBCAABvKCEAgDeUEADAG0oIAOANJQQA8IYSAgB4QwkBALyhhAAA3lBCAABvKCEAgDeUEADAG0oIAOANJQQA8IYSAgB4QwkBALyhhAAA3lBCAABvsnwv4NOcc5KklDol53kxAACzlDol/fnn+aUMuBJqaWmRJO3RTs8rAQB8ES0tLYpGo5fcJuT6UlWXUXd3t06cOKFIJKJQKNTrsUQioZKSEtXX1ysvL8/TCv3jOJzDcTiH43AOx+GcgXAcnHNqaWlRcXGxMjIu/azPgLsSysjI0Lhx4y65TV5e3rA+yc7jOJzDcTiH43AOx+Ec38fh866AzuOFCQAAbyghAIA3g6qEwuGwHnvsMYXDYd9L8YrjcA7H4RyOwzkch3MG23EYcC9MAAAMH4PqSggAMLRQQgAAbyghAIA3lBAAwJtBVUJPPfWUysrKNGLECN1000164403fC/pslq7dq1CoVCvWywW872sfrd7924tXLhQxcXFCoVCeuGFF3o97pzT2rVrVVxcrNzcXM2dO1eHDx/2s9h+9HnHYenSpRecH9OnT/ez2H5SWVmpqVOnKhKJqKCgQHfeeaeOHDnSa5vhcD705TgMlvNh0JTQ9u3btXLlSq1Zs0YHDx7UrbfeqoqKCh0/ftz30i6riRMnqqGhoed26NAh30vqd62trZoyZYo2btx40cefeOIJrV+/Xhs3btT+/fsVi8V0++2398whHCo+7zhI0oIFC3qdHzt3Dq0ZjDU1NVq2bJn27dunqqoqpVIplZeXq7W1tWeb4XA+9OU4SIPkfHCDxC233OIefPDBXvddd9117oc//KGnFV1+jz32mJsyZYrvZXglyT3//PM9X3d3d7tYLOYef/zxnvva29tdNBp1P/vZzzys8PL49HFwzrklS5a4O+64w8t6fGlqanKSXE1NjXNu+J4Pnz4Ozg2e82FQXAl1dHTowIEDKi8v73V/eXm59u7d62lVftTW1qq4uFhlZWW65557dPToUd9L8qqurk6NjY29zo1wOKw5c+YMu3NDkqqrq1VQUKAJEybo/vvvV1NTk+8l9at4PC5Jys/PlzR8z4dPH4fzBsP5MChK6OTJk+rq6lJhYWGv+wsLC9XY2OhpVZfftGnTtHXrVr3yyit6+umn1djYqJkzZ6q5udn30rw5//c/3M8NSaqoqNAzzzyjXbt26cknn9T+/fs1f/58JZNJ30vrF845rVq1SrNmzdKkSZMkDc/z4WLHQRo858OAm6J9KZ/+aAfn3AX3DWUVFRU9/z158mTNmDFDX/7yl7VlyxatWrXK48r8G+7nhiQtXry4578nTZqkm2++WaWlpdqxY4cWLVrkcWX9Y/ny5XrnnXe0Z8+eCx4bTufDZx2HwXI+DIoroTFjxigzM/OC32Sampou+I1nOBk1apQmT56s2tpa30vx5vyrAzk3LlRUVKTS0tIheX6sWLFCL730kl5//fVeH/0y3M6HzzoOFzNQz4dBUUI5OTm66aabVFVV1ev+qqoqzZw509Oq/Esmk3rvvfdUVFTkeynelJWVKRaL9To3Ojo6VFNTM6zPDUlqbm5WfX39kDo/nHNavny5nnvuOe3atUtlZWW9Hh8u58PnHYeLGbDng8cXRZg8++yzLjs72/3iF79w7777rlu5cqUbNWqUO3bsmO+lXTYPP/ywq66udkePHnX79u1z3/zmN10kEhnyx6ClpcUdPHjQHTx40Ely69evdwcPHnQffPCBc865xx9/3EWjUffcc8+5Q4cOuXvvvdcVFRW5RCLheeXpdanj0NLS4h5++GG3d+9eV1dX515//XU3Y8YMd/XVVw+p4/D973/fRaNRV11d7RoaGnpuZ8+e7dlmOJwPn3ccBtP5MGhKyDnnfvrTn7rS0lKXk5Pjbrzxxl4vRxwOFi9e7IqKilx2drYrLi52ixYtcocPH/a9rH73+uuvO0kX3JYsWeKcO/ey3Mcee8zFYjEXDofd7Nmz3aFDh/wuuh9c6jicPXvWlZeXu7Fjx7rs7Gx3zTXXuCVLlrjjx4/7XnZaXezPL8lt3ry5Z5vhcD583nEYTOcDH+UAAPBmUDwnBAAYmighAIA3lBAAwBtKCADgDSUEAPCGEgIAeEMJAQC8oYQAAN5QQgAAbyghAIA3lBAAwBtKCADgzf8DCTTz4LFHB6oAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torchvision.datasets import FashionMNIST\n",
    "\n",
    "fashion_mnist = {}\n",
    "fashion_mnist['train'] = FashionMNIST(root='~/data', train=True, download=True)\n",
    "fashion_mnist['test'] = FashionMNIST(root='~/data', train=False, download=True)\n",
    "\n",
    "print(fashion_mnist['train'].data.shape, fashion_mnist['train'].targets.shape)\n",
    "print(fashion_mnist['test'].data.shape, fashion_mnist['test'].targets.shape)\n",
    "\n",
    "display(pd.DataFrame({\n",
    "    'train' : pd.Series(fashion_mnist['train'].targets).value_counts(),\n",
    "    'test' : pd.Series(fashion_mnist['test'].targets).value_counts()\n",
    "}).T)\n",
    "\n",
    "# sample 1개 시각화\n",
    "plt.imshow(fashion_mnist['train'].data[0].numpy().reshape(28, 28))\n",
    "# data에 대한 설명\n",
    "fashion_mnist['train'].classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3313ea60",
   "metadata": {},
   "source": [
    "Q: 형식과 유형이 동일한 서로 다른 내용의 데이터 셋에 같은 모형을 적용하면?\n",
    "\n",
    "결과적으로는 정확도가 떨어지네...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbcdc2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_11\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_11\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ rescaling_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Rescaling</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">39,250</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ rescaling_3 (\u001b[38;5;33mRescaling\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_33 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │        \u001b[38;5;34m39,250\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_34 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │         \u001b[38;5;34m5,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_35 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,010\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">45,360</span> (177.19 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m45,360\u001b[0m (177.19 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">45,360</span> (177.19 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m45,360\u001b[0m (177.19 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.6939 - loss: 0.8074\n",
      "Epoch 2/10\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 18ms/step - accuracy: 0.8213 - loss: 0.4841\n",
      "Epoch 3/10\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - accuracy: 0.8447 - loss: 0.4246\n",
      "Epoch 4/10\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - accuracy: 0.8552 - loss: 0.3921\n",
      "Epoch 5/10\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - accuracy: 0.8637 - loss: 0.3704\n",
      "Epoch 6/10\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - accuracy: 0.8707 - loss: 0.3519\n",
      "Epoch 7/10\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 24ms/step - accuracy: 0.8736 - loss: 0.3412\n",
      "Epoch 8/10\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - accuracy: 0.8784 - loss: 0.3295\n",
      "Epoch 9/10\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - accuracy: 0.8808 - loss: 0.3200\n",
      "Epoch 10/10\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - accuracy: 0.8836 - loss: 0.3122\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.8689 - loss: 0.3677\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Loss        0.367665\n",
       "Accuracy    0.868900\n",
       "dtype: float64"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "train_data = fashion_mnist['train'].data\n",
    "train_target = np.array(fashion_mnist['train'].targets)\n",
    "test_data = fashion_mnist['test'].data\n",
    "test_target = np.array(fashion_mnist['test'].targets)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.Input(shape=(28, 28)),\n",
    "    # 전처리\n",
    "    layers.Rescaling(scale=1.0/255), # 정규화\n",
    "    layers.Flatten(), # 2차원 데이터를 1차원으로 펼침\n",
    "    # 은닉층\n",
    "    layers.Dense(units=50,  activation='sigmoid'), # nn.Linear + nn.Sigmoid\n",
    "    layers.Dense(units=100, activation='sigmoid'),\n",
    "    # 출력층\n",
    "    layers.Dense(units=10, activation='softmax') # softmax를 안하면, from_logits=True로 설정해야 함\n",
    "])\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False), \n",
    "    optimizer=keras.optimizers.SGD(learning_rate=1.0),\n",
    "    metrics=['accuracy'] # 평가지표 : 정확도\n",
    ") # 손실함수와 최적화 기법을 지정\n",
    "\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    train_target,\n",
    "    epochs=10,\n",
    "    batch_size=100,\n",
    ")\n",
    "\n",
    "#history = model.fit(mnist['train'].data, mnist['train'].targets, epochs=10, batch_size=100)\n",
    "\n",
    "# 평가\n",
    "test_loss, *metrics = model.evaluate(test_data, test_target)\n",
    "\n",
    "pd.Series({'Loss': test_loss, 'Accuracy': metrics[0]})\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
